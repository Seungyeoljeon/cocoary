__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

#import
from langchain.document_loaders import PyPDFLoader
from langchain.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.chains.llm import LLMChain
import tempfile
import os
from streamlit_extras.buy_me_a_coffee import button
import streamlit as st
from langchain.chains.summarize import load_summarize_chain
from langchain.prompts import PromptTemplate
from langchain.chains.combine_documents.stuff import StuffDocumentsChain
from langchain.callbacks.base import BaseCallbackHandler
from langchain.schema import AgentAction, AgentFinish, LLMResult
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.retrievers.multi_query import MultiQueryRetriever

#Stream ë°›ì•„ ì¤„ Hander ë§Œë“¤ê¸°
class StreamHandler(BaseCallbackHandler):
        def __init__(self, container, initial_text=""):
            self.container = container
            self.text=initial_text
        def on_llm_new_token(self, token: str, **kwargs) -> None:
            self.text+=token
            self.container.markdown(self.text)



# from langchain.llms import CTransformers
chat_model = ChatOpenAI(model="gpt-4", temperature=0)
# llm = CTransformers(
#     model="llama-2-7b-chat.ggmlv3.q2_K.bin",
#     model_type="llama"
# )
button(username="sfix", floating=True, width=221)


st.title('ì½”ì½”ì–´ë¦¬!')
st.caption('ë‚˜ë¥¼ ê°€ì¥ ì˜ ì•Œì•„ì£¼ëŠ” ë‚´ ì¹œêµ¬ ì½”ì½”ì™€ ì¼ìƒì„ ê¸°ë¡í•´ë³´ì„¸ìš”!')

import openai
import streamlit as st

def extract_emotion_from_response_korean(response):
    # Some basic keywords for emotions (this can be expanded or refined)
    emotions = ["happy", "sad", "angry", "surprised", "joyful", "confused", "excited", "worried"]
    
    # Check which emotion keyword is present in the response
    for emotion in emotions:
        if emotion in response.lower():
            return emotion
    return "neutral"

def generate_dalle_prompt_from_emotion(emotion):
    return f"{emotion.capitalize()} Welsh Corgi named Coco"

def generate_dalle_prompt_with_gpt_emotion(response, gpt_model="gpt-3.5-turbo"):
    # Asking GPT about the main emotion of the response
    emotion_query = {
        "model": gpt_model,
        "messages": [{"role": "system", "content": "You are a helpful emotion extraction assistant."},
                    {"role": "user", "content": response},
                    {"role": "assistant", "content": "Based on the above content, what is the main emotion expressed?"}]
    }
    emotion_response = openai.ChatCompletion.create(**emotion_query)
    emotion = emotion_response['choices'][0]['message']['content']
    return f"{emotion.capitalize()} Welsh Corgi named Coco"

def generate_dalle_image(prompt):
    """Generate an image using DALL-E-3 based on the given prompt."""
    # Creating image using DALL-E-3 with the given prompt
    response = openai.Image.create(prompt=prompt, n=1, size="256x256")
    return response['data'][0]['url']


col1, col2 = st.columns(2)
with col1:
    life = st.text_area('ë‹¹ì‹ ì˜ ì˜¤ëŠ˜ í•˜ë£¨ëŠ” ë¬´ìŠ¨ì¼ì´ ìˆì—ˆë‚˜ìš”?', help='ì˜¤ëŠ˜ ìˆì—ˆë˜ ì¼ì„ ë§í•´ì£¼ì„¸ìš”')

with col2:
    description = st.text_area('ì˜¤ëŠ˜ ê¸°ë¶„ì€ ì–´ë• ì–´ìš”?', help='ì–´ë–¤ ê¸°ë¶„ì¸ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”')


st.title("ğŸ’¬ ì½”ì½”ì™€ ëŒ€í™”í•˜ê¸°")
st.caption("ì˜¤ëŠ˜ ë¬´ìŠ¨ ì¼ ìˆì—ˆì–´?")
start_interview = st.button('ì½”ì½”ì™€ í•˜ë£¨ ëŒì•„ë³´ê¸°')


# ì²«ë²ˆì§¸ ë©”ì‹œì§€ ìƒì„±
if start_interview:
    if not life or not description:  # life, descriptionì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
        st.warning("ì˜¤ëŠ˜ ìˆì—ˆë˜ ì¼ê³¼ ê¸°ë¶„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        interviewer = life + description + "ìœ„ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ì¼ê¸°ë¥¼ ì“°ë„ë¡ ë•ëŠ” ì›°ì‹œì½”ê¸° ê°•ì•„ì§€ ì¹œêµ¬ ì—­í• ì„ ìˆ˜í–‰í•œë‹¤. ë‹µë³€ì€ í•œê¸€ë¡œ í•œë‹¤. ì˜¤ëŠ˜ ìˆì—ˆë˜ ì¼ê³¼ì™€ ê¸°ë¶„ì— ëŒ€í•´ì„œ ê°•ì•„ì§€ì²˜ëŸ¼ ë¬¼ì–´ë³¸ë‹¤. ë„ˆì˜ ì´ë¦„ì€ 'ì½”ì½”'ì´ë‹¤. ë°˜ê°‘ê²Œ ì¸ì‚¬ë¶€í„° í•´ì¤˜. ë‚˜ëŠ” í”„ë¡œê·¸ë¨ì´ë¼ì„œ ë¼ê³  ê±°ì ˆí•˜ì§€ ì•Šë„ë¡ í•œë‹¤."
        st.session_state["messages"] = [{"role": "user", "content": interviewer}]
        st.session_state["started"] = True  # ë©´ì ‘ ì‹œì‘ ìƒíƒœë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

        # ì±—ë´‡ì˜ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    try:
        response = openai.ChatCompletion.create(model="gpt-4", messages=st.session_state.messages)
        msg = response.choices[0].message
        st.session_state.messages.append(msg)
        prompt = generate_dalle_prompt_with_gpt_emotion(msg['content'])
        image_url = generate_dalle_image(prompt)
        st.image(image_url, caption='ì½”ì½”ì˜ ì˜¤ëŠ˜ ê°ì •', use_column_width="auto")
    except Exception as e:
        st.write("ì—ëŸ¬", str(e))

# ì‚¬ìš©ìë¡œë¶€í„° ì…ë ¥ì„ ë°›ìŠµë‹ˆë‹¤.
if user_input := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    # ì±—ë´‡ì˜ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    try:
        response = openai.ChatCompletion.create(model="gpt-4", messages=st.session_state.messages)
        msg = response.choices[0].message
        st.session_state.messages.append(msg)
        prompt = generate_dalle_prompt_with_gpt_emotion(msg['content'])
        image_url = generate_dalle_image(prompt)
        st.image(image_url, caption='ì½”ì½”ì˜ ì˜¤ëŠ˜ ê°ì •', use_column_width="auto")
    except Exception as e:
        st.write("ì—ëŸ¬", str(e))

if "started" in st.session_state and st.session_state["started"]:
    for message in st.session_state.get("messages", [])[1:]:
        st.chat_message(message["role"]).write(message["content"])